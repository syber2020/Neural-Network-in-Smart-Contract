{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alive-rally",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Perceptron\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "df = pd.read_csv('diabetes.csv',sep = ',')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "demanding-spoke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>62</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>67</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43</td>\n",
       "      <td>228</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  \\\n",
       "0            6      148             72             35        0   33   \n",
       "1            1       85             66             29        0   26   \n",
       "2            8      183             64              0        0   23   \n",
       "3            1       89             66             23       94   28   \n",
       "4            0      137             40             35      168   43   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                        62   50        1  \n",
       "1                        35   31        0  \n",
       "2                        67   32        1  \n",
       "3                        16   21        0  \n",
       "4                       228   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DiabetesPedigreeFunction'] = df['DiabetesPedigreeFunction']*100\n",
    "df.DiabetesPedigreeFunction = df.DiabetesPedigreeFunction.astype(int)\n",
    "df.BMI = df.BMI.astype(int) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "valued-burton",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = df.to_numpy()\n",
    "\n",
    "X = dataset[:500,0:8]\n",
    "X1 = dataset[500:,0:8]\n",
    "y = dataset[:500,8]\n",
    "y1 = dataset[500:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "parliamentary-breach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6 148  72  35   0  33  62  50]\n",
      " [  1  85  66  29   0  26  35  31]\n",
      " [  8 183  64   0   0  23  67  32]\n",
      " [  1  89  66  23  94  28  16  21]\n",
      " [  0 137  40  35 168  43 228  33]]\n",
      "[1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(X[:5])\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "grateful-influence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "# model.add(Dense(12, input_dim=8, activation='sigmoid'))\n",
    "# model.add(Dense(8, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "worthy-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "least-harvey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Dense.call of <keras.layers.core.Dense object at 0x000001F87FF2DAC0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpfvcpudlj.py, line 48)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Dense.call of <keras.layers.core.Dense object at 0x000001F87FF2DAC0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpfvcpudlj.py, line 48)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "50/50 [==============================] - 16s 564us/step - loss: 16.0654 - accuracy: 0.4919\n",
      "Epoch 2/150\n",
      "50/50 [==============================] - 0s 516us/step - loss: 11.5091 - accuracy: 0.6018\n",
      "Epoch 3/150\n",
      "50/50 [==============================] - 0s 500us/step - loss: 11.6237 - accuracy: 0.5846\n",
      "Epoch 4/150\n",
      "50/50 [==============================] - 0s 489us/step - loss: 12.2413 - accuracy: 0.5270\n",
      "Epoch 5/150\n",
      "50/50 [==============================] - 0s 507us/step - loss: 8.1529 - accuracy: 0.5819\n",
      "Epoch 6/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 6.9357 - accuracy: 0.6064\n",
      "Epoch 7/150\n",
      "50/50 [==============================] - 0s 473us/step - loss: 6.6036 - accuracy: 0.6093\n",
      "Epoch 8/150\n",
      "50/50 [==============================] - 0s 692us/step - loss: 6.2484 - accuracy: 0.6096\n",
      "Epoch 9/150\n",
      "50/50 [==============================] - 0s 530us/step - loss: 5.8055 - accuracy: 0.6425\n",
      "Epoch 10/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 4.8106 - accuracy: 0.5914\n",
      "Epoch 11/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 5.0592 - accuracy: 0.5549\n",
      "Epoch 12/150\n",
      "50/50 [==============================] - 0s 487us/step - loss: 4.5646 - accuracy: 0.6021\n",
      "Epoch 13/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 4.4831 - accuracy: 0.5913\n",
      "Epoch 14/150\n",
      "50/50 [==============================] - 0s 499us/step - loss: 4.7072 - accuracy: 0.5997\n",
      "Epoch 15/150\n",
      "50/50 [==============================] - 0s 530us/step - loss: 3.5561 - accuracy: 0.6317\n",
      "Epoch 16/150\n",
      "50/50 [==============================] - 0s 488us/step - loss: 3.7916 - accuracy: 0.5644\n",
      "Epoch 17/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 3.3721 - accuracy: 0.5909\n",
      "Epoch 18/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 3.3855 - accuracy: 0.5895\n",
      "Epoch 19/150\n",
      "50/50 [==============================] - 0s 487us/step - loss: 2.5880 - accuracy: 0.6179\n",
      "Epoch 20/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 2.9911 - accuracy: 0.5732\n",
      "Epoch 21/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 2.3964 - accuracy: 0.6466\n",
      "Epoch 22/150\n",
      "50/50 [==============================] - 0s 529us/step - loss: 2.5955 - accuracy: 0.6011\n",
      "Epoch 23/150\n",
      "50/50 [==============================] - 0s 525us/step - loss: 2.2410 - accuracy: 0.5800\n",
      "Epoch 24/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 2.0449 - accuracy: 0.5609\n",
      "Epoch 25/150\n",
      "50/50 [==============================] - 0s 508us/step - loss: 2.0940 - accuracy: 0.5663\n",
      "Epoch 26/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 2.0684 - accuracy: 0.5765\n",
      "Epoch 27/150\n",
      "50/50 [==============================] - 0s 530us/step - loss: 1.5605 - accuracy: 0.6031\n",
      "Epoch 28/150\n",
      "50/50 [==============================] - 0s 508us/step - loss: 1.5964 - accuracy: 0.5576\n",
      "Epoch 29/150\n",
      "50/50 [==============================] - 0s 491us/step - loss: 1.2785 - accuracy: 0.6068\n",
      "Epoch 30/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 1.1510 - accuracy: 0.5868\n",
      "Epoch 31/150\n",
      "50/50 [==============================] - 0s 517us/step - loss: 1.0661 - accuracy: 0.5713\n",
      "Epoch 32/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.8784 - accuracy: 0.5847\n",
      "Epoch 33/150\n",
      "50/50 [==============================] - 0s 522us/step - loss: 0.9164 - accuracy: 0.5300\n",
      "Epoch 34/150\n",
      "50/50 [==============================] - 0s 472us/step - loss: 0.8309 - accuracy: 0.5914\n",
      "Epoch 35/150\n",
      "50/50 [==============================] - 0s 512us/step - loss: 0.7663 - accuracy: 0.6094\n",
      "Epoch 36/150\n",
      "50/50 [==============================] - 0s 495us/step - loss: 0.6738 - accuracy: 0.6345\n",
      "Epoch 37/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.6904 - accuracy: 0.6330\n",
      "Epoch 38/150\n",
      "50/50 [==============================] - 0s 488us/step - loss: 0.6913 - accuracy: 0.6007\n",
      "Epoch 39/150\n",
      "50/50 [==============================] - 0s 500us/step - loss: 0.6481 - accuracy: 0.6571\n",
      "Epoch 40/150\n",
      "50/50 [==============================] - 0s 518us/step - loss: 0.6496 - accuracy: 0.6558\n",
      "Epoch 41/150\n",
      "50/50 [==============================] - 0s 489us/step - loss: 0.6747 - accuracy: 0.6226\n",
      "Epoch 42/150\n",
      "50/50 [==============================] - 0s 483us/step - loss: 0.6199 - accuracy: 0.6639\n",
      "Epoch 43/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.6323 - accuracy: 0.6434\n",
      "Epoch 44/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.6211 - accuracy: 0.6788\n",
      "Epoch 45/150\n",
      "50/50 [==============================] - 0s 486us/step - loss: 0.6143 - accuracy: 0.6725\n",
      "Epoch 46/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.6198 - accuracy: 0.6779\n",
      "Epoch 47/150\n",
      "50/50 [==============================] - 0s 506us/step - loss: 0.6381 - accuracy: 0.6687\n",
      "Epoch 48/150\n",
      "50/50 [==============================] - 0s 503us/step - loss: 0.6142 - accuracy: 0.6861\n",
      "Epoch 49/150\n",
      "50/50 [==============================] - 0s 509us/step - loss: 0.6166 - accuracy: 0.6930\n",
      "Epoch 50/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.6002 - accuracy: 0.6951\n",
      "Epoch 51/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.6021 - accuracy: 0.6956\n",
      "Epoch 52/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.5724 - accuracy: 0.7235\n",
      "Epoch 53/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.6207 - accuracy: 0.6818\n",
      "Epoch 54/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.5844 - accuracy: 0.6989\n",
      "Epoch 55/150\n",
      "50/50 [==============================] - 0s 469us/step - loss: 0.6207 - accuracy: 0.6543\n",
      "Epoch 56/150\n",
      "50/50 [==============================] - 0s 469us/step - loss: 0.5909 - accuracy: 0.7131\n",
      "Epoch 57/150\n",
      "50/50 [==============================] - 0s 493us/step - loss: 0.5690 - accuracy: 0.7170\n",
      "Epoch 58/150\n",
      "50/50 [==============================] - 0s 499us/step - loss: 0.6307 - accuracy: 0.6818\n",
      "Epoch 59/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.6075 - accuracy: 0.6875\n",
      "Epoch 60/150\n",
      "50/50 [==============================] - 0s 489us/step - loss: 0.6292 - accuracy: 0.6506\n",
      "Epoch 61/150\n",
      "50/50 [==============================] - 0s 507us/step - loss: 0.6080 - accuracy: 0.6952\n",
      "Epoch 62/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.6065 - accuracy: 0.6912\n",
      "Epoch 63/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.6189 - accuracy: 0.6589\n",
      "Epoch 64/150\n",
      "50/50 [==============================] - 0s 517us/step - loss: 0.6431 - accuracy: 0.6414\n",
      "Epoch 65/150\n",
      "50/50 [==============================] - 0s 530us/step - loss: 0.6138 - accuracy: 0.6762\n",
      "Epoch 66/150\n",
      "50/50 [==============================] - 0s 530us/step - loss: 0.6262 - accuracy: 0.6525\n",
      "Epoch 67/150\n",
      "50/50 [==============================] - 0s 469us/step - loss: 0.6290 - accuracy: 0.6666\n",
      "Epoch 68/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.5984 - accuracy: 0.7106\n",
      "Epoch 69/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.6172 - accuracy: 0.6864\n",
      "Epoch 70/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.6212 - accuracy: 0.6634\n",
      "Epoch 71/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.5877 - accuracy: 0.7125\n",
      "Epoch 72/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 510us/step - loss: 0.6058 - accuracy: 0.7102\n",
      "Epoch 73/150\n",
      "50/50 [==============================] - 0s 528us/step - loss: 0.5916 - accuracy: 0.6862\n",
      "Epoch 74/150\n",
      "50/50 [==============================] - 0s 496us/step - loss: 0.6110 - accuracy: 0.7081\n",
      "Epoch 75/150\n",
      "50/50 [==============================] - 0s 509us/step - loss: 0.6037 - accuracy: 0.6924\n",
      "Epoch 76/150\n",
      "50/50 [==============================] - 0s 476us/step - loss: 0.6085 - accuracy: 0.6753\n",
      "Epoch 77/150\n",
      "50/50 [==============================] - 0s 508us/step - loss: 0.6059 - accuracy: 0.6877\n",
      "Epoch 78/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.6160 - accuracy: 0.7121\n",
      "Epoch 79/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.6045 - accuracy: 0.6283\n",
      "Epoch 80/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.6626 - accuracy: 0.6328\n",
      "Epoch 81/150\n",
      "50/50 [==============================] - 0s 449us/step - loss: 0.6054 - accuracy: 0.7093\n",
      "Epoch 82/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.5903 - accuracy: 0.6888\n",
      "Epoch 83/150\n",
      "50/50 [==============================] - 0s 489us/step - loss: 0.6110 - accuracy: 0.6757\n",
      "Epoch 84/150\n",
      "50/50 [==============================] - 0s 530us/step - loss: 0.5874 - accuracy: 0.7002\n",
      "Epoch 85/150\n",
      "50/50 [==============================] - 0s 489us/step - loss: 0.6013 - accuracy: 0.6975\n",
      "Epoch 86/150\n",
      "50/50 [==============================] - 0s 504us/step - loss: 0.5817 - accuracy: 0.7087\n",
      "Epoch 87/150\n",
      "50/50 [==============================] - 0s 494us/step - loss: 0.5888 - accuracy: 0.7064\n",
      "Epoch 88/150\n",
      "50/50 [==============================] - 0s 518us/step - loss: 0.5981 - accuracy: 0.6918\n",
      "Epoch 89/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.6172 - accuracy: 0.6817\n",
      "Epoch 90/150\n",
      "50/50 [==============================] - 0s 469us/step - loss: 0.5788 - accuracy: 0.7033\n",
      "Epoch 91/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.5708 - accuracy: 0.7122\n",
      "Epoch 92/150\n",
      "50/50 [==============================] - 0s 486us/step - loss: 0.5941 - accuracy: 0.7039\n",
      "Epoch 93/150\n",
      "50/50 [==============================] - 0s 497us/step - loss: 0.5840 - accuracy: 0.7201\n",
      "Epoch 94/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.6243 - accuracy: 0.6517\n",
      "Epoch 95/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.5904 - accuracy: 0.7005\n",
      "Epoch 96/150\n",
      "50/50 [==============================] - 0s 507us/step - loss: 0.6194 - accuracy: 0.6807\n",
      "Epoch 97/150\n",
      "50/50 [==============================] - 0s 517us/step - loss: 0.5993 - accuracy: 0.6878\n",
      "Epoch 98/150\n",
      "50/50 [==============================] - 0s 524us/step - loss: 0.5862 - accuracy: 0.7111\n",
      "Epoch 99/150\n",
      "50/50 [==============================] - 0s 489us/step - loss: 0.5484 - accuracy: 0.7263\n",
      "Epoch 100/150\n",
      "50/50 [==============================] - 0s 509us/step - loss: 0.6136 - accuracy: 0.6895\n",
      "Epoch 101/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.5919 - accuracy: 0.7027\n",
      "Epoch 102/150\n",
      "50/50 [==============================] - 0s 504us/step - loss: 0.5771 - accuracy: 0.7435\n",
      "Epoch 103/150\n",
      "50/50 [==============================] - 0s 479us/step - loss: 0.5806 - accuracy: 0.6728\n",
      "Epoch 104/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.6073 - accuracy: 0.6840\n",
      "Epoch 105/150\n",
      "50/50 [==============================] - 0s 513us/step - loss: 0.6214 - accuracy: 0.6787\n",
      "Epoch 106/150\n",
      "50/50 [==============================] - 0s 487us/step - loss: 0.6024 - accuracy: 0.7072\n",
      "Epoch 107/150\n",
      "50/50 [==============================] - 0s 499us/step - loss: 0.6021 - accuracy: 0.7083\n",
      "Epoch 108/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.5865 - accuracy: 0.7180\n",
      "Epoch 109/150\n",
      "50/50 [==============================] - 0s 489us/step - loss: 0.6136 - accuracy: 0.6883\n",
      "Epoch 110/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.5629 - accuracy: 0.7336\n",
      "Epoch 111/150\n",
      "50/50 [==============================] - 0s 479us/step - loss: 0.6099 - accuracy: 0.7132\n",
      "Epoch 112/150\n",
      "50/50 [==============================] - 0s 508us/step - loss: 0.5727 - accuracy: 0.7147\n",
      "Epoch 113/150\n",
      "50/50 [==============================] - 0s 504us/step - loss: 0.5946 - accuracy: 0.6944\n",
      "Epoch 114/150\n",
      "50/50 [==============================] - 0s 499us/step - loss: 0.6006 - accuracy: 0.6950\n",
      "Epoch 115/150\n",
      "50/50 [==============================] - 0s 526us/step - loss: 0.5840 - accuracy: 0.7050\n",
      "Epoch 116/150\n",
      "50/50 [==============================] - 0s 551us/step - loss: 0.6101 - accuracy: 0.6943\n",
      "Epoch 117/150\n",
      "50/50 [==============================] - 0s 530us/step - loss: 0.5837 - accuracy: 0.7027\n",
      "Epoch 118/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.5934 - accuracy: 0.6999\n",
      "Epoch 119/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.5915 - accuracy: 0.7125\n",
      "Epoch 120/150\n",
      "50/50 [==============================] - 0s 513us/step - loss: 0.6114 - accuracy: 0.6788\n",
      "Epoch 121/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.5794 - accuracy: 0.7033\n",
      "Epoch 122/150\n",
      "50/50 [==============================] - 0s 469us/step - loss: 0.5927 - accuracy: 0.7099\n",
      "Epoch 123/150\n",
      "50/50 [==============================] - 0s 507us/step - loss: 0.5988 - accuracy: 0.7211\n",
      "Epoch 124/150\n",
      "50/50 [==============================] - 0s 489us/step - loss: 0.6122 - accuracy: 0.6686\n",
      "Epoch 125/150\n",
      "50/50 [==============================] - 0s 494us/step - loss: 0.5761 - accuracy: 0.7316\n",
      "Epoch 126/150\n",
      "50/50 [==============================] - 0s 530us/step - loss: 0.5961 - accuracy: 0.6876\n",
      "Epoch 127/150\n",
      "50/50 [==============================] - 0s 458us/step - loss: 0.5929 - accuracy: 0.7124\n",
      "Epoch 128/150\n",
      "50/50 [==============================] - 0s 521us/step - loss: 0.5975 - accuracy: 0.7155\n",
      "Epoch 129/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.5685 - accuracy: 0.7109\n",
      "Epoch 130/150\n",
      "50/50 [==============================] - 0s 495us/step - loss: 0.5831 - accuracy: 0.7113\n",
      "Epoch 131/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.5812 - accuracy: 0.6973\n",
      "Epoch 132/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.5903 - accuracy: 0.7012\n",
      "Epoch 133/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.5823 - accuracy: 0.7173\n",
      "Epoch 134/150\n",
      "50/50 [==============================] - 0s 506us/step - loss: 0.5991 - accuracy: 0.7030\n",
      "Epoch 135/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.5765 - accuracy: 0.7170\n",
      "Epoch 136/150\n",
      "50/50 [==============================] - 0s 530us/step - loss: 0.6063 - accuracy: 0.7189\n",
      "Epoch 137/150\n",
      "50/50 [==============================] - 0s 512us/step - loss: 0.5797 - accuracy: 0.7173\n",
      "Epoch 138/150\n",
      "50/50 [==============================] - 0s 496us/step - loss: 0.5907 - accuracy: 0.7112\n",
      "Epoch 139/150\n",
      "50/50 [==============================] - 0s 551us/step - loss: 0.5752 - accuracy: 0.6993\n",
      "Epoch 140/150\n",
      "50/50 [==============================] - 0s 530us/step - loss: 0.5962 - accuracy: 0.6940\n",
      "Epoch 141/150\n",
      "50/50 [==============================] - 0s 530us/step - loss: 0.5837 - accuracy: 0.7374\n",
      "Epoch 142/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.5608 - accuracy: 0.7247\n",
      "Epoch 143/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.5614 - accuracy: 0.7414\n",
      "Epoch 144/150\n",
      "50/50 [==============================] - 0s 475us/step - loss: 0.5970 - accuracy: 0.7015\n",
      "Epoch 145/150\n",
      "50/50 [==============================] - 0s 499us/step - loss: 0.5645 - accuracy: 0.7322\n",
      "Epoch 146/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.5827 - accuracy: 0.7344\n",
      "Epoch 147/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.5582 - accuracy: 0.7541\n",
      "Epoch 148/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.5733 - accuracy: 0.6897\n",
      "Epoch 149/150\n",
      "50/50 [==============================] - 0s 474us/step - loss: 0.5621 - accuracy: 0.7103\n",
      "Epoch 150/150\n",
      "50/50 [==============================] - 0s 551us/step - loss: 0.6133 - accuracy: 0.6857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f85a3bc190>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4\n",
    "...\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "arranged-superior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (10, 1)                   9         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "lasting-karaoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5825 - accuracy: 0.7100\n",
      "Accuracy: 71.00\n"
     ]
    }
   ],
   "source": [
    "4\n",
    "...\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tested-hudson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 1, 'activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "[array([[ 0.12618084],\n",
      "       [ 0.01285846],\n",
      "       [-0.02704078],\n",
      "       [-0.00792562],\n",
      "       [ 0.00374048],\n",
      "       [ 0.0246079 ],\n",
      "       [ 0.00492873],\n",
      "       [-0.01995637]], dtype=float32), array([-1.309261], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers: \n",
    "    print(layer.get_config())\n",
    "    print(layer.get_weights())\n",
    "    \n",
    "    w = layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "directed-census",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = w[0]\n",
    "bias = w[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "intensive-princeton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2 117  90  19  71  25  31  21]\n"
     ]
    }
   ],
   "source": [
    "print(X1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "statutory-response",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1791322 ],\n",
       "       [0.17203066],\n",
       "       [0.09800997],\n",
       "       [0.37826806],\n",
       "       [0.13135988],\n",
       "       [0.24628094],\n",
       "       [0.2773531 ],\n",
       "       [0.48242855],\n",
       "       [0.39304528],\n",
       "       [0.20902029],\n",
       "       [0.27507162],\n",
       "       [0.41901138],\n",
       "       [0.2123878 ],\n",
       "       [0.25319558],\n",
       "       [0.32373428],\n",
       "       [0.46372846],\n",
       "       [0.43021452],\n",
       "       [0.24906304],\n",
       "       [0.43630904],\n",
       "       [0.352709  ],\n",
       "       [0.13271984],\n",
       "       [0.30285114],\n",
       "       [0.6185833 ],\n",
       "       [0.46607983],\n",
       "       [0.36959523],\n",
       "       [0.22052759],\n",
       "       [0.20693585],\n",
       "       [0.27764994],\n",
       "       [0.35633853],\n",
       "       [0.20711812],\n",
       "       [0.44219565],\n",
       "       [0.26406443],\n",
       "       [0.24007985],\n",
       "       [0.72299397],\n",
       "       [0.31294954],\n",
       "       [0.7972342 ],\n",
       "       [0.0756124 ],\n",
       "       [0.06541875],\n",
       "       [0.37143633],\n",
       "       [0.29987955],\n",
       "       [0.47478965],\n",
       "       [0.44906756],\n",
       "       [0.21098307],\n",
       "       [0.16851485],\n",
       "       [0.15185434],\n",
       "       [0.62894416],\n",
       "       [0.6768811 ],\n",
       "       [0.457049  ],\n",
       "       [0.19393906],\n",
       "       [0.21270779],\n",
       "       [0.18810558],\n",
       "       [0.27370054],\n",
       "       [0.1191695 ],\n",
       "       [0.21550459],\n",
       "       [0.2636744 ],\n",
       "       [0.44372174],\n",
       "       [0.15371236],\n",
       "       [0.21078858],\n",
       "       [0.4013826 ],\n",
       "       [0.3448636 ],\n",
       "       [0.23033747],\n",
       "       [0.71501696],\n",
       "       [0.22167486],\n",
       "       [0.35262352],\n",
       "       [0.1470348 ],\n",
       "       [0.3747592 ],\n",
       "       [0.21259156],\n",
       "       [0.28513002],\n",
       "       [0.41515222],\n",
       "       [0.29276666],\n",
       "       [0.15730965],\n",
       "       [0.15048808],\n",
       "       [0.33930707],\n",
       "       [0.35118815],\n",
       "       [0.5111632 ],\n",
       "       [0.3824411 ],\n",
       "       [0.5660706 ],\n",
       "       [0.32118452],\n",
       "       [0.47208476],\n",
       "       [0.2106582 ],\n",
       "       [0.20276988],\n",
       "       [0.30744487],\n",
       "       [0.277398  ],\n",
       "       [0.29349092],\n",
       "       [0.7824589 ],\n",
       "       [0.21681955],\n",
       "       [0.45806274],\n",
       "       [0.29270095],\n",
       "       [0.42984587],\n",
       "       [0.45384175],\n",
       "       [0.4024989 ],\n",
       "       [0.2623089 ],\n",
       "       [0.22427464],\n",
       "       [0.46760345],\n",
       "       [0.51985896],\n",
       "       [0.5387675 ],\n",
       "       [0.09798336],\n",
       "       [0.44316638],\n",
       "       [0.31160802],\n",
       "       [0.4357089 ],\n",
       "       [0.12543568],\n",
       "       [0.6863446 ],\n",
       "       [0.14679512],\n",
       "       [0.43998218],\n",
       "       [0.835161  ],\n",
       "       [0.31623253],\n",
       "       [0.72303605],\n",
       "       [0.18002304],\n",
       "       [0.43520904],\n",
       "       [0.34098262],\n",
       "       [0.4498818 ],\n",
       "       [0.6568744 ],\n",
       "       [0.6778136 ],\n",
       "       [0.29114464],\n",
       "       [0.5851343 ],\n",
       "       [0.20755807],\n",
       "       [0.18551958],\n",
       "       [0.14809781],\n",
       "       [0.30598336],\n",
       "       [0.6452896 ],\n",
       "       [0.23468444],\n",
       "       [0.22744986],\n",
       "       [0.5162347 ],\n",
       "       [0.2747562 ],\n",
       "       [0.26781994],\n",
       "       [0.15601388],\n",
       "       [0.21914661],\n",
       "       [0.23856989],\n",
       "       [0.23359844],\n",
       "       [0.21630183],\n",
       "       [0.414584  ],\n",
       "       [0.16573179],\n",
       "       [0.28829652],\n",
       "       [0.28390372],\n",
       "       [0.38565987],\n",
       "       [0.4881666 ],\n",
       "       [0.17696473],\n",
       "       [0.2350871 ],\n",
       "       [0.40792537],\n",
       "       [0.13663515],\n",
       "       [0.17504278],\n",
       "       [0.3668087 ],\n",
       "       [0.263929  ],\n",
       "       [0.6734322 ],\n",
       "       [0.32364738],\n",
       "       [0.6801295 ],\n",
       "       [0.3755321 ],\n",
       "       [0.6554366 ],\n",
       "       [0.43632752],\n",
       "       [0.1810706 ],\n",
       "       [0.26353157],\n",
       "       [0.35734063],\n",
       "       [0.32722676],\n",
       "       [0.34269428],\n",
       "       [0.27622607],\n",
       "       [0.8688001 ],\n",
       "       [0.24681774],\n",
       "       [0.3214668 ],\n",
       "       [0.24619839],\n",
       "       [0.2369284 ],\n",
       "       [0.36347312],\n",
       "       [0.5644978 ],\n",
       "       [0.40418127],\n",
       "       [0.5179952 ],\n",
       "       [0.2946505 ],\n",
       "       [0.21284088],\n",
       "       [0.1423144 ],\n",
       "       [0.3117717 ],\n",
       "       [0.44502658],\n",
       "       [0.43849504],\n",
       "       [0.5738899 ],\n",
       "       [0.25152022],\n",
       "       [0.12163103],\n",
       "       [0.4911136 ],\n",
       "       [0.1740877 ],\n",
       "       [0.5841121 ],\n",
       "       [0.30007133],\n",
       "       [0.22350487],\n",
       "       [0.417062  ],\n",
       "       [0.4905455 ],\n",
       "       [0.1693125 ],\n",
       "       [0.33131206],\n",
       "       [0.28627926],\n",
       "       [0.2992987 ],\n",
       "       [0.09898961],\n",
       "       [0.441643  ],\n",
       "       [0.3295995 ],\n",
       "       [0.24771294],\n",
       "       [0.40589923],\n",
       "       [0.29661292],\n",
       "       [0.3194703 ],\n",
       "       [0.3914424 ],\n",
       "       [0.41151282],\n",
       "       [0.44080138],\n",
       "       [0.20401827],\n",
       "       [0.62497306],\n",
       "       [0.44557774],\n",
       "       [0.56539863],\n",
       "       [0.379935  ],\n",
       "       [0.4569501 ],\n",
       "       [0.3940852 ],\n",
       "       [0.20797354],\n",
       "       [0.20340288],\n",
       "       [0.70403624],\n",
       "       [0.26400495],\n",
       "       [0.18431741],\n",
       "       [0.7232671 ],\n",
       "       [0.71100897],\n",
       "       [0.44630563],\n",
       "       [0.39162493],\n",
       "       [0.7579855 ],\n",
       "       [0.23653641],\n",
       "       [0.5291877 ],\n",
       "       [0.54205096],\n",
       "       [0.18452233],\n",
       "       [0.9144265 ],\n",
       "       [0.55946815],\n",
       "       [0.23341367],\n",
       "       [0.37024072],\n",
       "       [0.15521517],\n",
       "       [0.11655387],\n",
       "       [0.4048945 ],\n",
       "       [0.30625078],\n",
       "       [0.24979922],\n",
       "       [0.09278774],\n",
       "       [0.1860522 ],\n",
       "       [0.3254684 ],\n",
       "       [0.19570428],\n",
       "       [0.28369534],\n",
       "       [0.2866229 ],\n",
       "       [0.2522087 ],\n",
       "       [0.32979614],\n",
       "       [0.46897176],\n",
       "       [0.4198466 ],\n",
       "       [0.12449694],\n",
       "       [0.26531032],\n",
       "       [0.21703294],\n",
       "       [0.20615974],\n",
       "       [0.43683338],\n",
       "       [0.1668579 ],\n",
       "       [0.54645854],\n",
       "       [0.4503302 ],\n",
       "       [0.33067045],\n",
       "       [0.33937752],\n",
       "       [0.71746945],\n",
       "       [0.35602874],\n",
       "       [0.21078506],\n",
       "       [0.22728339],\n",
       "       [0.62698317],\n",
       "       [0.38483536],\n",
       "       [0.48918977],\n",
       "       [0.2245031 ],\n",
       "       [0.23877269],\n",
       "       [0.6995501 ],\n",
       "       [0.35982308],\n",
       "       [0.24059558],\n",
       "       [0.22764933],\n",
       "       [0.15404311],\n",
       "       [0.19942209],\n",
       "       [0.28504163],\n",
       "       [0.2659294 ],\n",
       "       [0.5467047 ],\n",
       "       [0.31996262],\n",
       "       [0.28966725],\n",
       "       [0.25343513],\n",
       "       [0.33774245],\n",
       "       [0.22837725],\n",
       "       [0.15528184]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sharp-alliance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "33\n",
      "35\n",
      "45\n",
      "46\n",
      "61\n",
      "74\n",
      "76\n",
      "84\n",
      "94\n",
      "95\n",
      "101\n",
      "104\n",
      "106\n",
      "111\n",
      "112\n",
      "114\n",
      "119\n",
      "122\n",
      "143\n",
      "145\n",
      "147\n",
      "155\n",
      "161\n",
      "163\n",
      "170\n",
      "175\n",
      "195\n",
      "197\n",
      "203\n",
      "206\n",
      "207\n",
      "210\n",
      "212\n",
      "213\n",
      "215\n",
      "216\n",
      "240\n",
      "244\n",
      "248\n",
      "253\n",
      "261\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(predictions)):\n",
    "    if(predictions[i]>=.5):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "damaged-damages",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rounded= [round(x[0]) for x in predictions]\n",
    "rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "altered-korea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7164179104477612"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y1, rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "advance-jacksonville",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "universal-vanilla",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y1[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "interested-penguin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 126., 1000.],\n",
       "       [  12., 1000.],\n",
       "       [ -27., 1000.],\n",
       "       [  -7., 1000.],\n",
       "       [   3., 1000.],\n",
       "       [  24., 1000.],\n",
       "       [   4., 1000.],\n",
       "       [ -19., 1000.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.zeros((8,2))\n",
    "for i in range(weights.shape[0]):\n",
    "    w[i][0] = int(weights[i][0]*1000)\n",
    "    w[i][1] = 1000\n",
    "w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "marked-treatment",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.zeros((2,1))\n",
    "b[0][0] = int(bias*1000)\n",
    "b [1][0]= 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "designed-seventh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lcm(x, y):\n",
    "   # choose the greater number\n",
    "    if (x > y):\n",
    "        greater = x\n",
    "    else:\n",
    "        greater = y\n",
    "    while(True):\n",
    "        if((greater % x == 0) and (greater % y == 0)):\n",
    "            lcm = greater\n",
    "            break\n",
    "        greater += 1\n",
    "    return lcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "wired-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addition(a,b,c,d):\n",
    "    den = compute_lcm(b,d)\n",
    "#     den = b*d\n",
    "    num = ((den/b)*a) + ((den/d)*c)\n",
    "#     print(num,den)\n",
    "    return float(num),float(den)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "revised-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IXWB(inputs,w,b):\n",
    "    num=0\n",
    "    den=0\n",
    "    out = np.zeros((inputs.shape[0],1))\n",
    "    for i in range(inputs.shape[0]):\n",
    "#     for i in range(10):\n",
    "#         print(inputs[i][0],w)\n",
    "        for j in range(inputs.shape[1]):\n",
    "            num = num + inputs[i][j]*w[j][0]\n",
    "            den = w[0][1]\n",
    "        num,den = addition(num,den,b[0][0],b[1][0])\n",
    "        out[i][0] = num\n",
    "#         out[i][1] = den\n",
    "        num =0\n",
    "        den =0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "purple-jimmy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2 117  90  19  71  25  31  21]\n",
      "[[ 126. 1000.]\n",
      " [  12. 1000.]\n",
      " [ -27. 1000.]\n",
      " [  -7. 1000.]\n",
      " [   3. 1000.]\n",
      " [  24. 1000.]\n",
      " [   4. 1000.]\n",
      " [ -19. 1000.]]\n"
     ]
    }
   ],
   "source": [
    "print(X1[0])\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "elementary-journal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.678e+03]\n",
      " [-1.631e+03]\n",
      " [-2.231e+03]\n",
      " [-6.600e+02]\n",
      " [-1.938e+03]\n",
      " [-1.189e+03]\n",
      " [-1.168e+03]\n",
      " [-3.450e+02]\n",
      " [-6.270e+02]\n",
      " [-1.423e+03]\n",
      " [-1.012e+03]\n",
      " [-5.950e+02]\n",
      " [-1.365e+03]\n",
      " [-1.201e+03]\n",
      " [-8.720e+02]\n",
      " [-3.600e+02]\n",
      " [-5.330e+02]\n",
      " [-1.210e+03]\n",
      " [-3.180e+02]\n",
      " [-9.580e+02]\n",
      " [-1.960e+03]\n",
      " [-1.026e+03]\n",
      " [ 3.930e+02]\n",
      " [-2.840e+02]\n",
      " [-6.490e+02]\n",
      " [-1.352e+03]\n",
      " [-1.485e+03]\n",
      " [-1.119e+03]\n",
      " [-8.420e+02]\n",
      " [-1.481e+03]\n",
      " [-4.590e+02]\n",
      " [-1.181e+03]\n",
      " [-1.305e+03]\n",
      " [ 8.460e+02]\n",
      " [-9.770e+02]\n",
      " [ 1.230e+03]\n",
      " [-2.581e+03]\n",
      " [-2.722e+03]\n",
      " [-8.270e+02]\n",
      " [-1.105e+03]\n",
      " [-3.510e+02]\n",
      " [-4.730e+02]\n",
      " [-1.408e+03]\n",
      " [-1.699e+03]\n",
      " [-1.847e+03]\n",
      " [ 2.120e+02]\n",
      " [ 3.820e+02]\n",
      " [-3.940e+02]\n",
      " [-1.575e+03]\n",
      " [-1.483e+03]\n",
      " [-1.548e+03]\n",
      " [-1.146e+03]\n",
      " [-2.071e+03]\n",
      " [-1.410e+03]\n",
      " [-1.199e+03]\n",
      " [-4.540e+02]\n",
      " [-1.763e+03]\n",
      " [-1.395e+03]\n",
      " [-4.490e+02]\n",
      " [-7.260e+02]\n",
      " [-1.291e+03]\n",
      " [ 5.350e+02]\n",
      " [-1.390e+03]\n",
      " [-7.440e+02]\n",
      " [-1.882e+03]\n",
      " [-7.070e+02]\n",
      " [-1.418e+03]\n",
      " [-1.043e+03]\n",
      " [-5.530e+02]\n",
      " [-1.085e+03]\n",
      " [-1.750e+03]\n",
      " [-1.856e+03]\n",
      " [-8.000e+02]\n",
      " [-7.860e+02]\n",
      " [-3.700e+02]\n",
      " [-6.060e+02]\n",
      " [ 4.000e+01]\n",
      " [-9.160e+02]\n",
      " [-2.290e+02]\n",
      " [-1.410e+03]\n",
      " [-1.492e+03]\n",
      " [-8.870e+02]\n",
      " [-1.024e+03]\n",
      " [-9.630e+02]\n",
      " [ 7.230e+02]\n",
      " [-1.382e+03]\n",
      " [-2.820e+02]\n",
      " [-9.780e+02]\n",
      " [-5.980e+02]\n",
      " [-2.680e+02]\n",
      " [-5.220e+02]\n",
      " [-1.201e+03]\n",
      " [-1.367e+03]\n",
      " [-4.130e+02]\n",
      " [-2.080e+02]\n",
      " [-1.880e+02]\n",
      " [-2.275e+03]\n",
      " [-3.520e+02]\n",
      " [-9.310e+02]\n",
      " [-4.490e+02]\n",
      " [-2.044e+03]\n",
      " [ 6.950e+02]\n",
      " [-1.827e+03]\n",
      " [-4.680e+02]\n",
      " [ 1.463e+03]\n",
      " [-8.940e+02]\n",
      " [ 5.100e+02]\n",
      " [-1.632e+03]\n",
      " [-5.770e+02]\n",
      " [-8.790e+02]\n",
      " [-4.100e+02]\n",
      " [ 3.390e+02]\n",
      " [ 3.460e+02]\n",
      " [-1.027e+03]\n",
      " [ 1.190e+02]\n",
      " [-1.436e+03]\n",
      " [-1.579e+03]\n",
      " [-1.818e+03]\n",
      " [-9.790e+02]\n",
      " [ 4.870e+02]\n",
      " [-1.373e+03]\n",
      " [-1.425e+03]\n",
      " [-2.060e+02]\n",
      " [-1.146e+03]\n",
      " [-1.108e+03]\n",
      " [-1.787e+03]\n",
      " [-1.388e+03]\n",
      " [-1.306e+03]\n",
      " [-1.286e+03]\n",
      " [-1.353e+03]\n",
      " [-4.930e+02]\n",
      " [-1.749e+03]\n",
      " [-1.022e+03]\n",
      " [-1.157e+03]\n",
      " [-5.440e+02]\n",
      " [-1.610e+02]\n",
      " [-1.609e+03]\n",
      " [-1.346e+03]\n",
      " [-5.660e+02]\n",
      " [-1.947e+03]\n",
      " [-1.752e+03]\n",
      " [-6.790e+02]\n",
      " [-1.135e+03]\n",
      " [ 6.020e+02]\n",
      " [-9.660e+02]\n",
      " [ 3.220e+02]\n",
      " [-7.630e+02]\n",
      " [ 3.640e+02]\n",
      " [-4.360e+02]\n",
      " [-1.581e+03]\n",
      " [-1.169e+03]\n",
      " [-7.790e+02]\n",
      " [-8.620e+02]\n",
      " [-7.840e+02]\n",
      " [-1.138e+03]\n",
      " [ 1.363e+03]\n",
      " [-1.240e+03]\n",
      " [-1.042e+03]\n",
      " [-1.218e+03]\n",
      " [-1.373e+03]\n",
      " [-6.790e+02]\n",
      " [-2.000e+00]\n",
      " [-6.530e+02]\n",
      " [-1.470e+02]\n",
      " [-9.380e+02]\n",
      " [-1.474e+03]\n",
      " [-1.875e+03]\n",
      " [-8.520e+02]\n",
      " [-4.330e+02]\n",
      " [-4.140e+02]\n",
      " [ 2.600e+01]\n",
      " [-1.210e+03]\n",
      " [-2.050e+03]\n",
      " [-3.780e+02]\n",
      " [-1.643e+03]\n",
      " [ 1.560e+02]\n",
      " [-9.640e+02]\n",
      " [-1.344e+03]\n",
      " [-4.460e+02]\n",
      " [-3.520e+02]\n",
      " [-1.668e+03]\n",
      " [-8.430e+02]\n",
      " [-1.073e+03]\n",
      " [-9.980e+02]\n",
      " [-2.316e+03]\n",
      " [-5.210e+02]\n",
      " [-8.410e+02]\n",
      " [-1.189e+03]\n",
      " [-6.760e+02]\n",
      " [-1.089e+03]\n",
      " [-9.070e+02]\n",
      " [-5.810e+02]\n",
      " [-5.830e+02]\n",
      " [-4.160e+02]\n",
      " [-1.444e+03]\n",
      " [ 7.000e+01]\n",
      " [-4.480e+02]\n",
      " [ 1.610e+02]\n",
      " [-7.490e+02]\n",
      " [-3.570e+02]\n",
      " [-6.960e+02]\n",
      " [-1.435e+03]\n",
      " [-1.534e+03]\n",
      " [ 7.440e+02]\n",
      " [-1.174e+03]\n",
      " [-1.533e+03]\n",
      " [ 8.650e+02]\n",
      " [ 5.490e+02]\n",
      " [-3.440e+02]\n",
      " [-6.700e+02]\n",
      " [ 7.110e+02]\n",
      " [-1.288e+03]\n",
      " [ 1.100e+01]\n",
      " [-1.690e+02]\n",
      " [-1.569e+03]\n",
      " [ 1.886e+03]\n",
      " [-8.800e+01]\n",
      " [-1.267e+03]\n",
      " [-7.470e+02]\n",
      " [-1.756e+03]\n",
      " [-2.090e+03]\n",
      " [-6.240e+02]\n",
      " [-1.019e+03]\n",
      " [-1.254e+03]\n",
      " [-2.372e+03]\n",
      " [-1.541e+03]\n",
      " [-9.750e+02]\n",
      " [-1.545e+03]\n",
      " [-1.095e+03]\n",
      " [-9.990e+02]\n",
      " [-1.247e+03]\n",
      " [-8.290e+02]\n",
      " [-3.880e+02]\n",
      " [-5.450e+02]\n",
      " [-2.053e+03]\n",
      " [-1.089e+03]\n",
      " [-1.495e+03]\n",
      " [-1.416e+03]\n",
      " [-4.830e+02]\n",
      " [-1.703e+03]\n",
      " [-4.400e+01]\n",
      " [-3.670e+02]\n",
      " [-8.810e+02]\n",
      " [-8.280e+02]\n",
      " [ 6.370e+02]\n",
      " [-7.430e+02]\n",
      " [-1.441e+03]\n",
      " [-1.393e+03]\n",
      " [ 2.090e+02]\n",
      " [-5.890e+02]\n",
      " [-2.650e+02]\n",
      " [-1.380e+03]\n",
      " [-1.240e+03]\n",
      " [ 3.350e+02]\n",
      " [-6.940e+02]\n",
      " [-1.385e+03]\n",
      " [-1.317e+03]\n",
      " [-1.801e+03]\n",
      " [-1.493e+03]\n",
      " [-1.063e+03]\n",
      " [-1.143e+03]\n",
      " [ 4.900e+01]\n",
      " [-8.240e+02]\n",
      " [-1.046e+03]\n",
      " [-1.185e+03]\n",
      " [-8.460e+02]\n",
      " [-1.328e+03]\n",
      " [-1.767e+03]]\n"
     ]
    }
   ],
   "source": [
    "test = IXWB(X1,w,b)\n",
    "print(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "demonstrated-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(test)):\n",
    "#     if(test[i][0]>0):\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "passing-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidfrac(x):\n",
    "    if(x>=0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ignored-template",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-cc4542bb9d49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoidfrac\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "out=np.zeors(())\n",
    "for i in range(test.shape[0]):\n",
    "    out[i] = sigmoidfrac(test[i][0])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y1, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-optimum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-teens",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
