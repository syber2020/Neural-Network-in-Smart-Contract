{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "alive-rally",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Perceptron\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "df = pd.read_csv('diabetes.csv',sep = ',')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "demanding-spoke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>62</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>67</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43</td>\n",
       "      <td>228</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  \\\n",
       "0            6      148             72             35        0   33   \n",
       "1            1       85             66             29        0   26   \n",
       "2            8      183             64              0        0   23   \n",
       "3            1       89             66             23       94   28   \n",
       "4            0      137             40             35      168   43   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                        62   50        1  \n",
       "1                        35   31        0  \n",
       "2                        67   32        1  \n",
       "3                        16   21        0  \n",
       "4                       228   33        1  "
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DiabetesPedigreeFunction'] = df['DiabetesPedigreeFunction']*100\n",
    "df.DiabetesPedigreeFunction = df.DiabetesPedigreeFunction.astype(int)\n",
    "df.BMI = df.BMI.astype(int) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "valued-burton",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = df.to_numpy()\n",
    "\n",
    "X = dataset[:500,0:8]\n",
    "X1 = dataset[500:,0:8]\n",
    "y = dataset[:500,8]\n",
    "y1 = dataset[500:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "parliamentary-breach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6 148  72  35   0  33  62  50]\n",
      " [  1  85  66  29   0  26  35  31]\n",
      " [  8 183  64   0   0  23  67  32]\n",
      " [  1  89  66  23  94  28  16  21]\n",
      " [  0 137  40  35 168  43 228  33]]\n",
      "[1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(X[:5])\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "grateful-influence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "# model.add(Dense(12, input_dim=8, activation='sigmoid'))\n",
    "# model.add(Dense(8, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "worthy-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "least-harvey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "50/50 [==============================] - 1s 535us/step - loss: 16.1297 - accuracy: 0.6163\n",
      "Epoch 2/150\n",
      "50/50 [==============================] - 0s 506us/step - loss: 18.4375 - accuracy: 0.5385\n",
      "Epoch 3/150\n",
      "50/50 [==============================] - 0s 469us/step - loss: 13.6766 - accuracy: 0.5610\n",
      "Epoch 4/150\n",
      "50/50 [==============================] - 0s 489us/step - loss: 13.0671 - accuracy: 0.5775\n",
      "Epoch 5/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 13.0471 - accuracy: 0.5739\n",
      "Epoch 6/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 10.7761 - accuracy: 0.6076\n",
      "Epoch 7/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 11.0049 - accuracy: 0.6117\n",
      "Epoch 8/150\n",
      "50/50 [==============================] - 0s 487us/step - loss: 9.6265 - accuracy: 0.5908\n",
      "Epoch 9/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 8.7827 - accuracy: 0.5965\n",
      "Epoch 10/150\n",
      "50/50 [==============================] - 0s 503us/step - loss: 8.1379 - accuracy: 0.6402\n",
      "Epoch 11/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 8.1699 - accuracy: 0.6182\n",
      "Epoch 12/150\n",
      "50/50 [==============================] - 0s 521us/step - loss: 8.0934 - accuracy: 0.5883\n",
      "Epoch 13/150\n",
      "50/50 [==============================] - 0s 489us/step - loss: 6.8010 - accuracy: 0.5948\n",
      "Epoch 14/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 6.8685 - accuracy: 0.5722\n",
      "Epoch 15/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 6.8236 - accuracy: 0.5689\n",
      "Epoch 16/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 6.5643 - accuracy: 0.5550\n",
      "Epoch 17/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 6.1785 - accuracy: 0.5569\n",
      "Epoch 18/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 6.2999 - accuracy: 0.5210\n",
      "Epoch 19/150\n",
      "50/50 [==============================] - 0s 498us/step - loss: 5.2709 - accuracy: 0.5763\n",
      "Epoch 20/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 5.6104 - accuracy: 0.5531\n",
      "Epoch 21/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 5.3528 - accuracy: 0.5439\n",
      "Epoch 22/150\n",
      "50/50 [==============================] - 0s 530us/step - loss: 4.7133 - accuracy: 0.5622\n",
      "Epoch 23/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 5.3049 - accuracy: 0.5246\n",
      "Epoch 24/150\n",
      "50/50 [==============================] - 0s 522us/step - loss: 4.7919 - accuracy: 0.5308\n",
      "Epoch 25/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 4.5299 - accuracy: 0.5476\n",
      "Epoch 26/150\n",
      "50/50 [==============================] - 0s 489us/step - loss: 4.0635 - accuracy: 0.5694\n",
      "Epoch 27/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 3.9709 - accuracy: 0.5688\n",
      "Epoch 28/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 3.5953 - accuracy: 0.5572\n",
      "Epoch 29/150\n",
      "50/50 [==============================] - 0s 521us/step - loss: 3.8487 - accuracy: 0.5564\n",
      "Epoch 30/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 3.5503 - accuracy: 0.5350\n",
      "Epoch 31/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 3.6764 - accuracy: 0.5342\n",
      "Epoch 32/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 3.1345 - accuracy: 0.5965\n",
      "Epoch 33/150\n",
      "50/50 [==============================] - 0s 530us/step - loss: 3.3910 - accuracy: 0.5766\n",
      "Epoch 34/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 3.0344 - accuracy: 0.5663\n",
      "Epoch 35/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 2.6403 - accuracy: 0.5727\n",
      "Epoch 36/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 2.2292 - accuracy: 0.6271\n",
      "Epoch 37/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 2.8053 - accuracy: 0.5389\n",
      "Epoch 38/150\n",
      "50/50 [==============================] - 0s 509us/step - loss: 2.4910 - accuracy: 0.5583\n",
      "Epoch 39/150\n",
      "50/50 [==============================] - 0s 489us/step - loss: 2.4327 - accuracy: 0.5482\n",
      "Epoch 40/150\n",
      "50/50 [==============================] - 0s 489us/step - loss: 2.1691 - accuracy: 0.5962\n",
      "Epoch 41/150\n",
      "50/50 [==============================] - 0s 514us/step - loss: 2.0379 - accuracy: 0.5944\n",
      "Epoch 42/150\n",
      "50/50 [==============================] - 0s 481us/step - loss: 1.8556 - accuracy: 0.5924\n",
      "Epoch 43/150\n",
      "50/50 [==============================] - 0s 530us/step - loss: 1.8099 - accuracy: 0.5976\n",
      "Epoch 44/150\n",
      "50/50 [==============================] - 0s 501us/step - loss: 2.0137 - accuracy: 0.5549\n",
      "Epoch 45/150\n",
      "50/50 [==============================] - 0s 502us/step - loss: 1.7626 - accuracy: 0.5828\n",
      "Epoch 46/150\n",
      "50/50 [==============================] - 0s 551us/step - loss: 1.7319 - accuracy: 0.6024\n",
      "Epoch 47/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 1.5867 - accuracy: 0.5898\n",
      "Epoch 48/150\n",
      "50/50 [==============================] - 0s 551us/step - loss: 1.7184 - accuracy: 0.5824\n",
      "Epoch 49/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 1.4714 - accuracy: 0.5875\n",
      "Epoch 50/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 1.4801 - accuracy: 0.5497\n",
      "Epoch 51/150\n",
      "50/50 [==============================] - 0s 531us/step - loss: 1.3443 - accuracy: 0.5756\n",
      "Epoch 52/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 1.2386 - accuracy: 0.5797\n",
      "Epoch 53/150\n",
      "50/50 [==============================] - 0s 525us/step - loss: 1.2270 - accuracy: 0.6223\n",
      "Epoch 54/150\n",
      "50/50 [==============================] - 0s 515us/step - loss: 1.0678 - accuracy: 0.6116\n",
      "Epoch 55/150\n",
      "50/50 [==============================] - 0s 469us/step - loss: 1.0745 - accuracy: 0.6135\n",
      "Epoch 56/150\n",
      "50/50 [==============================] - 0s 514us/step - loss: 1.0798 - accuracy: 0.5770\n",
      "Epoch 57/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.9391 - accuracy: 0.6084\n",
      "Epoch 58/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 1.0037 - accuracy: 0.6254\n",
      "Epoch 59/150\n",
      "50/50 [==============================] - 0s 494us/step - loss: 0.9681 - accuracy: 0.6086\n",
      "Epoch 60/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.8884 - accuracy: 0.6099\n",
      "Epoch 61/150\n",
      "50/50 [==============================] - 0s 505us/step - loss: 0.9308 - accuracy: 0.5975\n",
      "Epoch 62/150\n",
      "50/50 [==============================] - 0s 523us/step - loss: 0.9212 - accuracy: 0.6119\n",
      "Epoch 63/150\n",
      "50/50 [==============================] - 0s 483us/step - loss: 0.8668 - accuracy: 0.6105\n",
      "Epoch 64/150\n",
      "50/50 [==============================] - 0s 509us/step - loss: 0.8365 - accuracy: 0.6252\n",
      "Epoch 65/150\n",
      "50/50 [==============================] - 0s 489us/step - loss: 0.8163 - accuracy: 0.6251\n",
      "Epoch 66/150\n",
      "50/50 [==============================] - 0s 499us/step - loss: 0.8407 - accuracy: 0.6287\n",
      "Epoch 67/150\n",
      "50/50 [==============================] - 0s 505us/step - loss: 0.7939 - accuracy: 0.6227\n",
      "Epoch 68/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.7729 - accuracy: 0.6210\n",
      "Epoch 69/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.6957 - accuracy: 0.6353\n",
      "Epoch 70/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.7384 - accuracy: 0.6201\n",
      "Epoch 71/150\n",
      "50/50 [==============================] - 0s 520us/step - loss: 0.6982 - accuracy: 0.6570\n",
      "Epoch 72/150\n",
      "50/50 [==============================] - 0s 529us/step - loss: 0.7208 - accuracy: 0.6668\n",
      "Epoch 73/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.7473 - accuracy: 0.6157\n",
      "Epoch 74/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.7115 - accuracy: 0.6431\n",
      "Epoch 75/150\n",
      "50/50 [==============================] - 0s 512us/step - loss: 0.6928 - accuracy: 0.6075\n",
      "Epoch 76/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.6616 - accuracy: 0.6752\n",
      "Epoch 77/150\n",
      "50/50 [==============================] - 0s 513us/step - loss: 0.6579 - accuracy: 0.6792\n",
      "Epoch 78/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.6812 - accuracy: 0.6092\n",
      "Epoch 79/150\n",
      "50/50 [==============================] - 0s 489us/step - loss: 0.6800 - accuracy: 0.6335\n",
      "Epoch 80/150\n",
      "50/50 [==============================] - 0s 506us/step - loss: 0.6447 - accuracy: 0.6746\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 501us/step - loss: 0.6690 - accuracy: 0.6373\n",
      "Epoch 82/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.6375 - accuracy: 0.6713\n",
      "Epoch 83/150\n",
      "50/50 [==============================] - 0s 530us/step - loss: 0.6538 - accuracy: 0.6513\n",
      "Epoch 84/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.6565 - accuracy: 0.6348\n",
      "Epoch 85/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.6693 - accuracy: 0.6475\n",
      "Epoch 86/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.6217 - accuracy: 0.6470\n",
      "Epoch 87/150\n",
      "50/50 [==============================] - 0s 508us/step - loss: 0.6074 - accuracy: 0.6839\n",
      "Epoch 88/150\n",
      "50/50 [==============================] - 0s 504us/step - loss: 0.6411 - accuracy: 0.6474\n",
      "Epoch 89/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.6507 - accuracy: 0.6418\n",
      "Epoch 90/150\n",
      "50/50 [==============================] - 0s 518us/step - loss: 0.6128 - accuracy: 0.6776\n",
      "Epoch 91/150\n",
      "50/50 [==============================] - 0s 509us/step - loss: 0.6000 - accuracy: 0.7069\n",
      "Epoch 92/150\n",
      "50/50 [==============================] - 0s 489us/step - loss: 0.6427 - accuracy: 0.6397\n",
      "Epoch 93/150\n",
      "50/50 [==============================] - 0s 530us/step - loss: 0.6271 - accuracy: 0.6924\n",
      "Epoch 94/150\n",
      "50/50 [==============================] - 0s 513us/step - loss: 0.6458 - accuracy: 0.6508\n",
      "Epoch 95/150\n",
      "50/50 [==============================] - 0s 489us/step - loss: 0.5879 - accuracy: 0.6863\n",
      "Epoch 96/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.5923 - accuracy: 0.7161\n",
      "Epoch 97/150\n",
      "50/50 [==============================] - 0s 489us/step - loss: 0.5985 - accuracy: 0.7002\n",
      "Epoch 98/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.5908 - accuracy: 0.7107\n",
      "Epoch 99/150\n",
      "50/50 [==============================] - 0s 485us/step - loss: 0.6231 - accuracy: 0.6676\n",
      "Epoch 100/150\n",
      "50/50 [==============================] - 0s 493us/step - loss: 0.6298 - accuracy: 0.6539\n",
      "Epoch 101/150\n",
      "50/50 [==============================] - 0s 562us/step - loss: 0.6024 - accuracy: 0.6824\n",
      "Epoch 102/150\n",
      "50/50 [==============================] - 0s 500us/step - loss: 0.6030 - accuracy: 0.7239\n",
      "Epoch 103/150\n",
      "50/50 [==============================] - 0s 571us/step - loss: 0.6099 - accuracy: 0.6760\n",
      "Epoch 104/150\n",
      "50/50 [==============================] - 0s 549us/step - loss: 0.5974 - accuracy: 0.6650\n",
      "Epoch 105/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.6195 - accuracy: 0.6784\n",
      "Epoch 106/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.5969 - accuracy: 0.7001\n",
      "Epoch 107/150\n",
      "50/50 [==============================] - 0s 551us/step - loss: 0.6555 - accuracy: 0.6473\n",
      "Epoch 108/150\n",
      "50/50 [==============================] - 0s 530us/step - loss: 0.6042 - accuracy: 0.6999\n",
      "Epoch 109/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.5978 - accuracy: 0.7167\n",
      "Epoch 110/150\n",
      "50/50 [==============================] - 0s 507us/step - loss: 0.5796 - accuracy: 0.7196\n",
      "Epoch 111/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.6087 - accuracy: 0.7017\n",
      "Epoch 112/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.6863 - accuracy: 0.6332\n",
      "Epoch 113/150\n",
      "50/50 [==============================] - 0s 534us/step - loss: 0.6342 - accuracy: 0.6428\n",
      "Epoch 114/150\n",
      "50/50 [==============================] - 0s 541us/step - loss: 0.5947 - accuracy: 0.6962\n",
      "Epoch 115/150\n",
      "50/50 [==============================] - 0s 495us/step - loss: 0.6006 - accuracy: 0.6909\n",
      "Epoch 116/150\n",
      "50/50 [==============================] - 0s 516us/step - loss: 0.6259 - accuracy: 0.6880\n",
      "Epoch 117/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.6070 - accuracy: 0.6809\n",
      "Epoch 118/150\n",
      "50/50 [==============================] - 0s 499us/step - loss: 0.6143 - accuracy: 0.6914\n",
      "Epoch 119/150\n",
      "50/50 [==============================] - 0s 551us/step - loss: 0.5944 - accuracy: 0.6698\n",
      "Epoch 120/150\n",
      "50/50 [==============================] - 0s 551us/step - loss: 0.5999 - accuracy: 0.6814\n",
      "Epoch 121/150\n",
      "50/50 [==============================] - 0s 530us/step - loss: 0.6113 - accuracy: 0.6886\n",
      "Epoch 122/150\n",
      "50/50 [==============================] - 0s 530us/step - loss: 0.5879 - accuracy: 0.6889\n",
      "Epoch 123/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.5820 - accuracy: 0.7239\n",
      "Epoch 124/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.5960 - accuracy: 0.6977\n",
      "Epoch 125/150\n",
      "50/50 [==============================] - 0s 535us/step - loss: 0.6034 - accuracy: 0.6975\n",
      "Epoch 126/150\n",
      "50/50 [==============================] - 0s 501us/step - loss: 0.5711 - accuracy: 0.7105\n",
      "Epoch 127/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.5855 - accuracy: 0.7009\n",
      "Epoch 128/150\n",
      "50/50 [==============================] - 0s 520us/step - loss: 0.6049 - accuracy: 0.7061\n",
      "Epoch 129/150\n",
      "50/50 [==============================] - 0s 479us/step - loss: 0.6152 - accuracy: 0.6618\n",
      "Epoch 130/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.5963 - accuracy: 0.7028\n",
      "Epoch 131/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.5892 - accuracy: 0.6952\n",
      "Epoch 132/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.6039 - accuracy: 0.6668\n",
      "Epoch 133/150\n",
      "50/50 [==============================] - 0s 485us/step - loss: 0.5728 - accuracy: 0.7098\n",
      "Epoch 134/150\n",
      "50/50 [==============================] - 0s 500us/step - loss: 0.5806 - accuracy: 0.7118\n",
      "Epoch 135/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.6137 - accuracy: 0.6920\n",
      "Epoch 136/150\n",
      "50/50 [==============================] - 0s 521us/step - loss: 0.6167 - accuracy: 0.6644\n",
      "Epoch 137/150\n",
      "50/50 [==============================] - 0s 512us/step - loss: 0.6317 - accuracy: 0.6918\n",
      "Epoch 138/150\n",
      "50/50 [==============================] - 0s 521us/step - loss: 0.5728 - accuracy: 0.7379\n",
      "Epoch 139/150\n",
      "50/50 [==============================] - 0s 528us/step - loss: 0.5684 - accuracy: 0.7356\n",
      "Epoch 140/150\n",
      "50/50 [==============================] - 0s 505us/step - loss: 0.5761 - accuracy: 0.7565\n",
      "Epoch 141/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.5779 - accuracy: 0.6864\n",
      "Epoch 142/150\n",
      "50/50 [==============================] - 0s 498us/step - loss: 0.5867 - accuracy: 0.7185\n",
      "Epoch 143/150\n",
      "50/50 [==============================] - 0s 522us/step - loss: 0.6039 - accuracy: 0.6800\n",
      "Epoch 144/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.5730 - accuracy: 0.7162\n",
      "Epoch 145/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.6326 - accuracy: 0.6982\n",
      "Epoch 146/150\n",
      "50/50 [==============================] - 0s 507us/step - loss: 0.6291 - accuracy: 0.6712\n",
      "Epoch 147/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.5783 - accuracy: 0.7393\n",
      "Epoch 148/150\n",
      "50/50 [==============================] - 0s 510us/step - loss: 0.5767 - accuracy: 0.7149\n",
      "Epoch 149/150\n",
      "50/50 [==============================] - 0s 517us/step - loss: 0.5881 - accuracy: 0.7237\n",
      "Epoch 150/150\n",
      "50/50 [==============================] - 0s 490us/step - loss: 0.6029 - accuracy: 0.7206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x248730bfc70>"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4\n",
    "...\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "arranged-superior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (10, 1)                   9         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "lasting-karaoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 534us/step - loss: 0.5879 - accuracy: 0.7160\n",
      "Accuracy: 71.60\n"
     ]
    }
   ],
   "source": [
    "4\n",
    "...\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "tested-hudson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 1, 'activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "[array([[ 0.13203669],\n",
      "       [ 0.01406144],\n",
      "       [-0.02519551],\n",
      "       [-0.00595888],\n",
      "       [ 0.00296422],\n",
      "       [ 0.02580162],\n",
      "       [ 0.00380746],\n",
      "       [-0.01828524]], dtype=float32), array([-1.1897464], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers: \n",
    "    print(layer.get_config())\n",
    "    print(layer.get_weights())\n",
    "    \n",
    "    w = layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "directed-census",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = w[0]\n",
    "bias = w[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "loving-technician",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2 117  90  19  71  25  31  21]\n"
     ]
    }
   ],
   "source": [
    "print(X1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "statutory-response",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25506896],\n",
       "       [0.25434548],\n",
       "       [0.1389032 ],\n",
       "       [0.4771852 ],\n",
       "       [0.20906636],\n",
       "       [0.34860092],\n",
       "       [0.39950514],\n",
       "       [0.5564039 ],\n",
       "       [0.45996436],\n",
       "       [0.3134054 ],\n",
       "       [0.40001443],\n",
       "       [0.49591318],\n",
       "       [0.3099665 ],\n",
       "       [0.32830822],\n",
       "       [0.41166165],\n",
       "       [0.58067226],\n",
       "       [0.5510434 ],\n",
       "       [0.36858624],\n",
       "       [0.55679405],\n",
       "       [0.42247438],\n",
       "       [0.18667176],\n",
       "       [0.4045139 ],\n",
       "       [0.6896741 ],\n",
       "       [0.59019935],\n",
       "       [0.48021555],\n",
       "       [0.2965233 ],\n",
       "       [0.27178997],\n",
       "       [0.36934075],\n",
       "       [0.43129376],\n",
       "       [0.2762888 ],\n",
       "       [0.5253137 ],\n",
       "       [0.35003254],\n",
       "       [0.31985378],\n",
       "       [0.77796435],\n",
       "       [0.37515676],\n",
       "       [0.8473319 ],\n",
       "       [0.11905357],\n",
       "       [0.09068435],\n",
       "       [0.44900745],\n",
       "       [0.39628193],\n",
       "       [0.5691699 ],\n",
       "       [0.53592163],\n",
       "       [0.31633657],\n",
       "       [0.24734026],\n",
       "       [0.21405882],\n",
       "       [0.73757106],\n",
       "       [0.7631978 ],\n",
       "       [0.558349  ],\n",
       "       [0.30270478],\n",
       "       [0.34176922],\n",
       "       [0.2752167 ],\n",
       "       [0.3491063 ],\n",
       "       [0.19301611],\n",
       "       [0.2875297 ],\n",
       "       [0.3341648 ],\n",
       "       [0.5459979 ],\n",
       "       [0.23434633],\n",
       "       [0.3147766 ],\n",
       "       [0.5557471 ],\n",
       "       [0.46050763],\n",
       "       [0.34412506],\n",
       "       [0.7840253 ],\n",
       "       [0.2986147 ],\n",
       "       [0.4506499 ],\n",
       "       [0.2033644 ],\n",
       "       [0.4445669 ],\n",
       "       [0.29890102],\n",
       "       [0.38504297],\n",
       "       [0.5347968 ],\n",
       "       [0.3796828 ],\n",
       "       [0.22353199],\n",
       "       [0.22551444],\n",
       "       [0.4405912 ],\n",
       "       [0.43594015],\n",
       "       [0.5690658 ],\n",
       "       [0.4915539 ],\n",
       "       [0.63791764],\n",
       "       [0.420756  ],\n",
       "       [0.60282546],\n",
       "       [0.3661919 ],\n",
       "       [0.31699437],\n",
       "       [0.4231242 ],\n",
       "       [0.41627622],\n",
       "       [0.41160256],\n",
       "       [0.79597825],\n",
       "       [0.28801882],\n",
       "       [0.5957239 ],\n",
       "       [0.39370716],\n",
       "       [0.5385162 ],\n",
       "       [0.5127211 ],\n",
       "       [0.54562867],\n",
       "       [0.36196387],\n",
       "       [0.32559782],\n",
       "       [0.50894   ],\n",
       "       [0.6080862 ],\n",
       "       [0.6306515 ],\n",
       "       [0.14551806],\n",
       "       [0.51799655],\n",
       "       [0.443969  ],\n",
       "       [0.50907993],\n",
       "       [0.1885589 ],\n",
       "       [0.7514133 ],\n",
       "       [0.23024693],\n",
       "       [0.5640288 ],\n",
       "       [0.8865301 ],\n",
       "       [0.42476112],\n",
       "       [0.7766287 ],\n",
       "       [0.24273193],\n",
       "       [0.5305615 ],\n",
       "       [0.41367018],\n",
       "       [0.5312463 ],\n",
       "       [0.73647004],\n",
       "       [0.7552669 ],\n",
       "       [0.3960192 ],\n",
       "       [0.697325  ],\n",
       "       [0.29116926],\n",
       "       [0.28087884],\n",
       "       [0.20198077],\n",
       "       [0.41579944],\n",
       "       [0.71579045],\n",
       "       [0.32437253],\n",
       "       [0.2859077 ],\n",
       "       [0.6393302 ],\n",
       "       [0.3550927 ],\n",
       "       [0.36068794],\n",
       "       [0.23652652],\n",
       "       [0.30280784],\n",
       "       [0.32987887],\n",
       "       [0.34578577],\n",
       "       [0.30574793],\n",
       "       [0.51946324],\n",
       "       [0.23752013],\n",
       "       [0.37828162],\n",
       "       [0.36668253],\n",
       "       [0.5003173 ],\n",
       "       [0.6118744 ],\n",
       "       [0.2631277 ],\n",
       "       [0.3084426 ],\n",
       "       [0.5102129 ],\n",
       "       [0.19471842],\n",
       "       [0.23234975],\n",
       "       [0.48181117],\n",
       "       [0.38997355],\n",
       "       [0.7294409 ],\n",
       "       [0.39970303],\n",
       "       [0.73505116],\n",
       "       [0.47731116],\n",
       "       [0.74038833],\n",
       "       [0.5717113 ],\n",
       "       [0.25997546],\n",
       "       [0.33644557],\n",
       "       [0.44665292],\n",
       "       [0.44761255],\n",
       "       [0.43772972],\n",
       "       [0.3614036 ],\n",
       "       [0.88060606],\n",
       "       [0.3291753 ],\n",
       "       [0.399697  ],\n",
       "       [0.38314843],\n",
       "       [0.3021108 ],\n",
       "       [0.5174744 ],\n",
       "       [0.6856923 ],\n",
       "       [0.54587656],\n",
       "       [0.6447892 ],\n",
       "       [0.42234254],\n",
       "       [0.29797158],\n",
       "       [0.23817232],\n",
       "       [0.44655582],\n",
       "       [0.5350485 ],\n",
       "       [0.5814147 ],\n",
       "       [0.678682  ],\n",
       "       [0.3282536 ],\n",
       "       [0.19380489],\n",
       "       [0.5799811 ],\n",
       "       [0.2612657 ],\n",
       "       [0.71296203],\n",
       "       [0.44103754],\n",
       "       [0.29967558],\n",
       "       [0.5287304 ],\n",
       "       [0.53701806],\n",
       "       [0.2244308 ],\n",
       "       [0.47122195],\n",
       "       [0.37343448],\n",
       "       [0.4047253 ],\n",
       "       [0.15430295],\n",
       "       [0.5238524 ],\n",
       "       [0.43316042],\n",
       "       [0.33952272],\n",
       "       [0.48399127],\n",
       "       [0.4090139 ],\n",
       "       [0.41986084],\n",
       "       [0.5622883 ],\n",
       "       [0.5059376 ],\n",
       "       [0.56748587],\n",
       "       [0.27623284],\n",
       "       [0.6850167 ],\n",
       "       [0.5636495 ],\n",
       "       [0.6318794 ],\n",
       "       [0.47273043],\n",
       "       [0.55884886],\n",
       "       [0.47934088],\n",
       "       [0.31519637],\n",
       "       [0.31206036],\n",
       "       [0.7743858 ],\n",
       "       [0.35851175],\n",
       "       [0.2801398 ],\n",
       "       [0.785519  ],\n",
       "       [0.7518905 ],\n",
       "       [0.59761345],\n",
       "       [0.46707776],\n",
       "       [0.79521745],\n",
       "       [0.34565586],\n",
       "       [0.66784644],\n",
       "       [0.59788746],\n",
       "       [0.265997  ],\n",
       "       [0.9315995 ],\n",
       "       [0.6555809 ],\n",
       "       [0.33741462],\n",
       "       [0.45587373],\n",
       "       [0.24080855],\n",
       "       [0.17800063],\n",
       "       [0.49094984],\n",
       "       [0.41035914],\n",
       "       [0.35772735],\n",
       "       [0.1463578 ],\n",
       "       [0.29083595],\n",
       "       [0.40786758],\n",
       "       [0.29083353],\n",
       "       [0.40253192],\n",
       "       [0.37352848],\n",
       "       [0.35178697],\n",
       "       [0.45077574],\n",
       "       [0.5936666 ],\n",
       "       [0.49699572],\n",
       "       [0.18222463],\n",
       "       [0.37040058],\n",
       "       [0.2925218 ],\n",
       "       [0.29225218],\n",
       "       [0.5109625 ],\n",
       "       [0.24246526],\n",
       "       [0.65959764],\n",
       "       [0.53554446],\n",
       "       [0.41347072],\n",
       "       [0.46992847],\n",
       "       [0.80531526],\n",
       "       [0.47868812],\n",
       "       [0.33191633],\n",
       "       [0.3011571 ],\n",
       "       [0.72248137],\n",
       "       [0.52198815],\n",
       "       [0.5827144 ],\n",
       "       [0.32272017],\n",
       "       [0.33566788],\n",
       "       [0.75129825],\n",
       "       [0.5116028 ],\n",
       "       [0.32534957],\n",
       "       [0.35664314],\n",
       "       [0.23128784],\n",
       "       [0.2828294 ],\n",
       "       [0.43910202],\n",
       "       [0.3435369 ],\n",
       "       [0.69870526],\n",
       "       [0.42689222],\n",
       "       [0.40658733],\n",
       "       [0.36120403],\n",
       "       [0.4418634 ],\n",
       "       [0.3200368 ],\n",
       "       [0.22672665]], dtype=float32)"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "cellular-lodge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "15\n",
      "16\n",
      "18\n",
      "22\n",
      "23\n",
      "30\n",
      "33\n",
      "35\n",
      "40\n",
      "41\n",
      "45\n",
      "46\n",
      "47\n",
      "55\n",
      "58\n",
      "61\n",
      "68\n",
      "74\n",
      "76\n",
      "78\n",
      "84\n",
      "86\n",
      "88\n",
      "89\n",
      "90\n",
      "93\n",
      "94\n",
      "95\n",
      "97\n",
      "99\n",
      "101\n",
      "103\n",
      "104\n",
      "106\n",
      "108\n",
      "110\n",
      "111\n",
      "112\n",
      "114\n",
      "119\n",
      "122\n",
      "130\n",
      "134\n",
      "135\n",
      "138\n",
      "143\n",
      "145\n",
      "147\n",
      "148\n",
      "155\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "168\n",
      "169\n",
      "170\n",
      "173\n",
      "175\n",
      "178\n",
      "179\n",
      "185\n",
      "191\n",
      "192\n",
      "193\n",
      "195\n",
      "196\n",
      "197\n",
      "199\n",
      "203\n",
      "206\n",
      "207\n",
      "208\n",
      "210\n",
      "212\n",
      "213\n",
      "215\n",
      "216\n",
      "232\n",
      "238\n",
      "240\n",
      "241\n",
      "244\n",
      "248\n",
      "249\n",
      "250\n",
      "253\n",
      "254\n",
      "261\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(predictions)):\n",
    "    if(predictions[i]>=.5):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "damaged-damages",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 703,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rounded= [round(x[0]) for x in predictions]\n",
    "rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "altered-korea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7089552238805971"
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y1, rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "advance-jacksonville",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "id": "universal-vanilla",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y1[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "id": "interested-penguin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 132., 1000.],\n",
       "       [  14., 1000.],\n",
       "       [ -25., 1000.],\n",
       "       [  -5., 1000.],\n",
       "       [   2., 1000.],\n",
       "       [  25., 1000.],\n",
       "       [   3., 1000.],\n",
       "       [ -18., 1000.]])"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.zeros((8,2))\n",
    "for i in range(weights.shape[0]):\n",
    "    w[i][0] = int(weights[i][0]*1000)\n",
    "    w[i][1] = 1000\n",
    "w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "id": "marked-treatment",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.zeros((2,1))\n",
    "b[0][0] = int(bias*1000)\n",
    "b [1][0]= 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "id": "according-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lcm(x, y):\n",
    "   # choose the greater number\n",
    "    if (x > y):\n",
    "        greater = x\n",
    "    else:\n",
    "        greater = y\n",
    "    while(True):\n",
    "        if((greater % x == 0) and (greater % y == 0)):\n",
    "            lcm = greater\n",
    "            break\n",
    "        greater += 1\n",
    "    return lcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "id": "pretty-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addition(a,b,c,d):\n",
    "    den = compute_lcm(b,d)\n",
    "#     den = b*d\n",
    "    num = ((den/b)*a) + ((den/d)*c)\n",
    "#     print(num,den)\n",
    "    return float(num),float(den)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "id": "false-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IXWB(inputs,w,b):\n",
    "    num=0\n",
    "    den=0\n",
    "    out = np.zeros((inputs.shape[0],1))\n",
    "    for i in range(inputs.shape[0]):\n",
    "#     for i in range(10):\n",
    "#         print(inputs[i][0],w)\n",
    "        for j in range(inputs.shape[1]):\n",
    "            num = num + inputs[i][j]*w[j][0]\n",
    "            den = w[0][1]\n",
    "        num,den = addition(num,den,b[0][0],b[1][0])\n",
    "        out[i][0] = num\n",
    "#         out[i][1] = den\n",
    "        num =0\n",
    "        den =0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "id": "incorporate-thumb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2 117  90  19  71  25  31  21]\n",
      "[[ 132. 1000.]\n",
      " [  14. 1000.]\n",
      " [ -25. 1000.]\n",
      " [  -5. 1000.]\n",
      " [   2. 1000.]\n",
      " [  25. 1000.]\n",
      " [   3. 1000.]\n",
      " [ -18. 1000.]]\n"
     ]
    }
   ],
   "source": [
    "print(X1[0])\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "id": "collective-arena",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1150.]\n",
      " [-1078.]\n",
      " [-1849.]\n",
      " [ -210.]\n",
      " [-1320.]\n",
      " [ -650.]\n",
      " [ -506.]\n",
      " [   17.]\n",
      " [ -302.]\n",
      " [ -810.]\n",
      " [ -400.]\n",
      " [ -226.]\n",
      " [ -811.]\n",
      " [ -766.]\n",
      " [ -442.]\n",
      " [  208.]\n",
      " [   16.]\n",
      " [ -568.]\n",
      " [  207.]\n",
      " [ -655.]\n",
      " [-1522.]\n",
      " [ -515.]\n",
      " [  785.]\n",
      " [  304.]\n",
      " [ -105.]\n",
      " [ -886.]\n",
      " [-1071.]\n",
      " [ -636.]\n",
      " [ -479.]\n",
      " [-1020.]\n",
      " [  -53.]\n",
      " [ -694.]\n",
      " [ -857.]\n",
      " [ 1194.]\n",
      " [ -649.]\n",
      " [ 1663.]\n",
      " [-2015.]\n",
      " [-2353.]\n",
      " [ -450.]\n",
      " [ -610.]\n",
      " [   46.]\n",
      " [  -70.]\n",
      " [ -806.]\n",
      " [-1168.]\n",
      " [-1382.]\n",
      " [  806.]\n",
      " [  898.]\n",
      " [   69.]\n",
      " [ -890.]\n",
      " [ -682.]\n",
      " [ -966.]\n",
      " [ -753.]\n",
      " [-1442.]\n",
      " [ -970.]\n",
      " [ -829.]\n",
      " [   -7.]\n",
      " [-1176.]\n",
      " [ -793.]\n",
      " [  235.]\n",
      " [ -187.]\n",
      " [ -658.]\n",
      " [  992.]\n",
      " [ -942.]\n",
      " [ -277.]\n",
      " [-1421.]\n",
      " [ -363.]\n",
      " [ -890.]\n",
      " [ -571.]\n",
      " [   10.]\n",
      " [ -649.]\n",
      " [-1272.]\n",
      " [-1255.]\n",
      " [ -298.]\n",
      " [ -387.]\n",
      " [  -92.]\n",
      " [  -91.]\n",
      " [  388.]\n",
      " [ -394.]\n",
      " [  392.]\n",
      " [ -507.]\n",
      " [ -772.]\n",
      " [ -307.]\n",
      " [ -337.]\n",
      " [ -382.]\n",
      " [  751.]\n",
      " [ -933.]\n",
      " [  367.]\n",
      " [ -455.]\n",
      " [  -68.]\n",
      " [   10.]\n",
      " [  133.]\n",
      " [ -683.]\n",
      " [ -767.]\n",
      " [ -200.]\n",
      " [  192.]\n",
      " [  301.]\n",
      " [-1797.]\n",
      " [    6.]\n",
      " [ -245.]\n",
      " [ -104.]\n",
      " [-1477.]\n",
      " [ 1075.]\n",
      " [-1186.]\n",
      " [  102.]\n",
      " [ 2016.]\n",
      " [ -331.]\n",
      " [  882.]\n",
      " [-1193.]\n",
      " [ -142.]\n",
      " [ -529.]\n",
      " [  -43.]\n",
      " [  800.]\n",
      " [  783.]\n",
      " [ -474.]\n",
      " [  668.]\n",
      " [ -910.]\n",
      " [ -954.]\n",
      " [-1397.]\n",
      " [ -419.]\n",
      " [  887.]\n",
      " [ -879.]\n",
      " [-1034.]\n",
      " [  443.]\n",
      " [ -729.]\n",
      " [ -596.]\n",
      " [-1217.]\n",
      " [ -857.]\n",
      " [ -752.]\n",
      " [ -655.]\n",
      " [ -816.]\n",
      " [   13.]\n",
      " [-1244.]\n",
      " [ -533.]\n",
      " [ -722.]\n",
      " [  -16.]\n",
      " [  412.]\n",
      " [-1042.]\n",
      " [ -914.]\n",
      " [ -100.]\n",
      " [-1462.]\n",
      " [-1340.]\n",
      " [ -111.]\n",
      " [ -463.]\n",
      " [  924.]\n",
      " [ -589.]\n",
      " [  602.]\n",
      " [ -253.]\n",
      " [  869.]\n",
      " [  174.]\n",
      " [-1041.]\n",
      " [ -778.]\n",
      " [ -345.]\n",
      " [ -279.]\n",
      " [ -296.]\n",
      " [ -697.]\n",
      " [ 1462.]\n",
      " [ -782.]\n",
      " [ -657.]\n",
      " [ -495.]\n",
      " [ -987.]\n",
      " [   56.]\n",
      " [  685.]\n",
      " [  -14.]\n",
      " [  453.]\n",
      " [ -305.]\n",
      " [ -969.]\n",
      " [-1162.]\n",
      " [ -203.]\n",
      " [  -55.]\n",
      " [  243.]\n",
      " [  551.]\n",
      " [ -759.]\n",
      " [-1471.]\n",
      " [   27.]\n",
      " [-1084.]\n",
      " [  871.]\n",
      " [ -252.]\n",
      " [ -884.]\n",
      " [   87.]\n",
      " [ -147.]\n",
      " [-1288.]\n",
      " [ -136.]\n",
      " [ -632.]\n",
      " [ -438.]\n",
      " [-1725.]\n",
      " [ -137.]\n",
      " [ -301.]\n",
      " [ -672.]\n",
      " [ -285.]\n",
      " [ -540.]\n",
      " [ -392.]\n",
      " [  222.]\n",
      " [ -126.]\n",
      " [  151.]\n",
      " [ -983.]\n",
      " [  325.]\n",
      " [  123.]\n",
      " [  501.]\n",
      " [ -305.]\n",
      " [  143.]\n",
      " [ -301.]\n",
      " [ -791.]\n",
      " [ -841.]\n",
      " [ 1183.]\n",
      " [ -674.]\n",
      " [ -935.]\n",
      " [ 1279.]\n",
      " [  773.]\n",
      " [  377.]\n",
      " [ -326.]\n",
      " [  958.]\n",
      " [ -672.]\n",
      " [  680.]\n",
      " [   96.]\n",
      " [-1030.]\n",
      " [ 2181.]\n",
      " [  412.]\n",
      " [ -699.]\n",
      " [ -353.]\n",
      " [-1156.]\n",
      " [-1538.]\n",
      " [ -235.]\n",
      " [ -491.]\n",
      " [ -687.]\n",
      " [-1785.]\n",
      " [ -883.]\n",
      " [ -571.]\n",
      " [ -912.]\n",
      " [ -425.]\n",
      " [ -541.]\n",
      " [ -696.]\n",
      " [ -224.]\n",
      " [  226.]\n",
      " [ -191.]\n",
      " [-1541.]\n",
      " [ -536.]\n",
      " [-1020.]\n",
      " [ -914.]\n",
      " [ -147.]\n",
      " [-1173.]\n",
      " [  478.]\n",
      " [   25.]\n",
      " [ -472.]\n",
      " [ -182.]\n",
      " [ 1213.]\n",
      " [ -194.]\n",
      " [ -710.]\n",
      " [ -963.]\n",
      " [  737.]\n",
      " [   72.]\n",
      " [  226.]\n",
      " [ -811.]\n",
      " [ -685.]\n",
      " [  618.]\n",
      " [   35.]\n",
      " [ -891.]\n",
      " [ -587.]\n",
      " [-1228.]\n",
      " [ -959.]\n",
      " [ -269.]\n",
      " [ -709.]\n",
      " [  820.]\n",
      " [ -307.]\n",
      " [ -518.]\n",
      " [ -586.]\n",
      " [ -344.]\n",
      " [ -787.]\n",
      " [-1231.]]\n"
     ]
    }
   ],
   "source": [
    "test = IXWB(X1,w,b)\n",
    "print(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "id": "wooden-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(test)):\n",
    "#     if(test[i][0]>0):\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "id": "passing-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidfrac(x):\n",
    "    if(x>=0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "id": "lovely-clearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(test.shape[0]):\n",
    "    out[i] = sigmoidfrac(test[i][0])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "id": "guilty-simpson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7425373134328358"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y1, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "id": "particular-richards",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-workshop",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-nepal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
